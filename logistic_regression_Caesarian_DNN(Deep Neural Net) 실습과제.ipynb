{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 5)\n",
      "(56, 1)\n"
     ]
    }
   ],
   "source": [
    "# logistic_regression_Caesarian.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "xy = np.loadtxt('caesarian.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "# train data set\n",
    "x_data = xy[:56, :-1 ]\n",
    "y_data = xy[:56, [-1] ]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1  :  은닉층 (hidden layer)\n",
    "\n",
    "# (56,5) * (5,2) = (2,2)\n",
    "W1 = tf.Variable(tf.random.normal([5,2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([2]), name='bias1')\n",
    "\n",
    "def layer1(X):\n",
    "    return tf.sigmoid(tf.matmul(X,W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2  :  은닉층 (hidden layer)\n",
    "\n",
    "# (2,2) * (2,3) = (3,3)\n",
    "W2 = tf.Variable(tf.random.normal([2,3]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([3]), name='bias2')\n",
    "\n",
    "def layer2(X):\n",
    "    return tf.nn.relu(tf.matmul(layer1(X),W2) + b2)  # relu 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 3  :  출력층 (output layer)\n",
    "\n",
    "# (3,3) * (3,1) = (56,1)\n",
    "W3 = tf.Variable(tf.random.normal([3,1]), name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal([1]), name='bias3')\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.sigmoid(tf.matmul(layer2(X),W3) + b3)   # 2진 분류니까 sigmoid 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 : logloss\n",
    "def cost_func():\n",
    "    cost = -tf.reduce_mean(y_train*tf.math.log(hypothesis(x_train)) + (1-y_train)*\n",
    "                       tf.math.log(1-hypothesis(x_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 경사 하강법\n",
    "# learning rate (학습율) 을 0.01로 설정하여  optimizer객체를 생성\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost:[ 0.7865862 ]  W1: [[-0.18130666 -0.9502798 ]\n",
      " [-0.04064044 -0.74254024]\n",
      " [ 1.3241522  -0.61854756]\n",
      " [ 0.85306644 -0.08899867]\n",
      " [ 2.4478698   0.76250845]]  b1: [0.22552879 0.81065565]\n",
      "1000 cost:[ 0.62825996 ]  W1: [[-0.2101066  -0.9584141 ]\n",
      " [-0.6480036  -0.74293226]\n",
      " [ 2.0107837  -0.6165274 ]\n",
      " [ 0.8432495  -0.0869942 ]\n",
      " [ 2.0977902   0.7640387 ]]  b1: [0.79401064 0.8101392 ]\n",
      "2000 cost:[ 0.58548343 ]  W1: [[-0.26089105 -0.9887479 ]\n",
      " [-0.5793569  -0.7446999 ]\n",
      " [ 2.3928657  -0.6161741 ]\n",
      " [ 0.8947952  -0.0881521 ]\n",
      " [ 1.988508    0.7643712 ]]  b1: [1.7615236 0.8082863]\n",
      "3000 cost:[ 0.5528555 ]  W1: [[-0.3282179  -1.005098  ]\n",
      " [-0.39410412 -0.74566865]\n",
      " [ 2.6070874  -0.61610746]\n",
      " [ 0.99809587 -0.08892482]\n",
      " [ 2.1509013   0.7645521 ]]  b1: [2.7365665  0.80727255]\n",
      "4000 cost:[ 0.52890295 ]  W1: [[-0.390655   -1.0152597 ]\n",
      " [-0.33562335 -0.7462805 ]\n",
      " [ 2.9054728  -0.61610746]\n",
      " [ 1.0966209  -0.0894775 ]\n",
      " [ 2.4063005   0.76459074]]  b1: [3.588047  0.8066421]\n",
      "5000 cost:[ 0.5157112 ]  W1: [[-0.44637325 -1.0228231 ]\n",
      " [-0.30045727 -0.7467573 ]\n",
      " [ 3.2879078  -0.61610746]\n",
      " [ 1.2184824  -0.08991665]\n",
      " [ 2.717982    0.76459074]]  b1: [4.207501   0.80616146]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    # cost를 minimize 한다\n",
    "    optimizer.minimize(cost_func,var_list=[W1,b1,W2,b2,W3,b3])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W1:',W1.numpy(),' b1:',b1.numpy())\n",
    "        \n",
    "print('***** Learning Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[-0.44637325 -1.0228231 ]\n",
      " [-0.30045727 -0.7467573 ]\n",
      " [ 3.2879078  -0.61610746]\n",
      " [ 1.2184824  -0.08991665]\n",
      " [ 2.717982    0.76459074]]\n",
      "bias: [4.207501   0.80616146]\n",
      "weight2: [[ 1.0749263  -4.4403706   3.685213  ]\n",
      " [-2.2409484   0.08111266 -0.10699831]]\n",
      "bias2: [-0.00970369  0.7202491  -1.0796356 ]\n",
      "weight3: [[-0.8278286]\n",
      " [ 4.7168303]\n",
      " [ 6.2135777]]\n",
      "bias3: [-2.9793634]\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수, weight과 bias 출력\n",
    "print('weight:', W1.numpy())\n",
    "print('bias:', b1.numpy())\n",
    "\n",
    "print('weight2:', W2.numpy())\n",
    "print('bias2:', b2.numpy())\n",
    "\n",
    "print('weight3:', W3.numpy())\n",
    "print('bias3:', b3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.45833334\n"
     ]
    }
   ],
   "source": [
    "# accuracy computation (정확도 측정)\n",
    "# test data set\n",
    "x_data = xy[56:, :-1 ]\n",
    "y_data = xy[56:, [-1] ]\n",
    "\n",
    "x_test = np.array(x_data,dtype=np.float32)\n",
    "y_test = np.array(y_data,dtype=np.float32)\n",
    "\n",
    "def predict(X):\n",
    "    return tf.cast(hypothesis(X) > 0.5, dtype = tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict(x_test),y_test),\n",
    "                                     dtype = tf.float32))\n",
    "# print(\"Hypothesis:\\n\",hypothesis(x_test).numpy(), \n",
    "#       \"\\nPredict:\\n\",predict(x_test).numpy())\n",
    "\n",
    "print(\"\\nAccuracy:\",accuracy.numpy()) # Accuracy: 0.45833334\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.45833334\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
