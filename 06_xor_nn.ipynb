{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c111cd24",
   "metadata": {},
   "source": [
    "## 다층 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bc22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor_nn\n",
    "# 2진 분류 : Logistic Regression\n",
    "# 활성화 함수 : sigmoid 함수 사용\n",
    "# two Layers of Neural Network\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "# train data set \n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]    # (4,2)\n",
    "\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]      # (4,1)\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9554dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1  :  은닉층 (hidden layer)\n",
    "\n",
    "# (4,2) * (2,2) = (4,2)\n",
    "W1 = tf.Variable(tf.random.normal([2,2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([2]), name='bias1')\n",
    "\n",
    "def layer1(X):\n",
    "    return tf.sigmoid(tf.matmul(X,W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6856399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2  :  출력층 (output layer)\n",
    "\n",
    "# (4,2) * (2,1) = (4,1)\n",
    "W2 = tf.Variable(tf.random.normal([2,1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name='bias2')\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.sigmoid(tf.matmul(layer1(X),W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da71056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수 : logloss, 2진 분류 모델\n",
    "\n",
    "def cost_func():\n",
    "    cost = -tf.reduce_mean(y_train*tf.math.log(hypothesis(x_train)) + (1 - y_train) * tf.math.log(1-hypothesis(x_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082ee788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01로 설정하여 optimizer 객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e72fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost:[ 0.70409703 ]  W1: [[-0.19030488 -0.9402918 ]\n",
      " [-0.04963874 -0.73254627]]  b1: [0.21652977 0.8206513 ]\n",
      "1000 cost:[ 0.025501736 ]  W1: [[-5.0247602 -6.6669364]\n",
      " [-4.994727  -6.503276 ]]  b1: [7.5096498 2.9154744]\n",
      "2000 cost:[ 0.0068961703 ]  W1: [[-5.9448414 -7.5746756]\n",
      " [-5.917538  -7.41493  ]]  b1: [8.922688 3.408214]\n",
      "3000 cost:[ 0.002987126 ]  W1: [[-6.4519587 -8.081454 ]\n",
      " [-6.426094  -7.923082 ]]  b1: [9.694396  3.6749146]\n",
      "4000 cost:[ 0.0015255437 ]  W1: [[-6.8228335 -8.45376  ]\n",
      " [-6.797981  -8.296075 ]]  b1: [10.256574   3.8682895]\n",
      "5000 cost:[ 0.00084184005 ]  W1: [[-7.1278057 -8.760636 ]\n",
      " [-7.103756  -8.603343 ]]  b1: [10.717851  4.026454]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    # cost를 minimize 한다\n",
    "    optimizer.minimize(cost_func,var_list=[W1,b1,W2,b2])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W1:',W1.numpy(),' b1:',b1.numpy())\n",
    "        \n",
    "print('***** Learning Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e7c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[-7.1278057 -8.760636 ]\n",
      " [-7.103756  -8.603343 ]]\n",
      "bias: [10.717851  4.026454]\n",
      "weight2: [[ 15.241018]\n",
      " [-14.880688]]\n",
      "bias2: [-7.5699553]\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수, weight과 bias 출력\n",
    "print('weight:', W1.numpy())\n",
    "print('bias:', b1.numpy())\n",
    "\n",
    "print('weight2:', W2.numpy())\n",
    "print('bias2:', b2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c52f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:\n",
      " [[9.5847249e-04]\n",
      " [9.9919164e-01]\n",
      " [9.9920160e-01]\n",
      " [8.0075860e-04]] \n",
      "Predict:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정 : accuracy computation\n",
    "def predict(X):\n",
    "    return tf.cast(hypothesis(X) > 0.5, dtype=tf.float32)  # 예측값을 0과 1로 변환\n",
    "\n",
    "# train 데이터로 검증\n",
    "preds = predict(x_train)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y_train), dtype=tf.float32))\n",
    "\n",
    "print(\"Hypothesis:\\n\",hypothesis(x_train).numpy(), \n",
    "      \"\\nPredict:\\n\",predict(x_train).numpy(),\n",
    "      \"\\nAccuracy:\",accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f29e2",
   "metadata": {},
   "source": [
    "## relu 사용 3층 신경망 구현\n",
    ": 은닉층의 활성화함수로 'relu'가 자주 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb8f15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1  :  은닉층 (hidden layer)\n",
    "\n",
    "# (4,2) * (2,5) = (4,5)\n",
    "W1 = tf.Variable(tf.random.normal([2,5]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([5]), name='bias1')\n",
    "\n",
    "def layer1(X):\n",
    "    return tf.nn.relu(tf.matmul(X,W1) + b1)   # relu 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8593a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2  :  은닉층 (hidden layer)\n",
    "\n",
    "# (4,5) * (5,3) = (4,3)\n",
    "W2 = tf.Variable(tf.random.normal([5,3]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([3]), name='bias2')\n",
    "\n",
    "def layer2(X):\n",
    "    return tf.nn.relu(tf.matmul(layer1(X),W2) + b2)  # relu 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e17c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 3  :  출력층 (output layer)\n",
    "\n",
    "# (4,3) * (3,1) = (4,1)\n",
    "W3 = tf.Variable(tf.random.normal([3,1]), name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal([1]), name='bias3')\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.sigmoid(tf.matmul(layer2(X),W3) + b3)   # 2진 분류니까 sigmoid 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28784b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수 : logloss, 2진 분류 모델\n",
    "\n",
    "def cost_func():\n",
    "    cost = -tf.reduce_mean(y_train*tf.math.log(hypothesis(x_train)) + (1 - y_train) * tf.math.log(1-hypothesis(x_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36e449b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01로 설정하여 optimizer 객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9aaab123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost:[ 0.746548 ]  W1: [[-0.77025205  0.9678269   0.3351241   0.33134714  1.2331858 ]\n",
      " [ 0.5865573   0.4092037   0.69737315 -1.365058   -0.8992608 ]]  b1: [-1.0226775 -1.2956215 -0.8273043 -1.2653481  1.0896453]\n",
      "1000 cost:[ 0.0089238575 ]  W1: [[-0.77025205  0.8590644   0.22303277  0.33134714  2.627257  ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -2.6268322 ]]  b1: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1626413]\n",
      "2000 cost:[ 0.0021715688 ]  W1: [[-0.77025205  0.8590644   0.22303277  0.33134714  2.8540933 ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -2.8527272 ]]  b1: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1524502]\n",
      "3000 cost:[ 0.00088857533 ]  W1: [[-0.77025205  0.8590644   0.22303277  0.33134714  2.9796188 ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -2.9788907 ]]  b1: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1497401]\n",
      "4000 cost:[ 0.00043612008 ]  W1: [[-0.77025205  0.8590644   0.22303277  0.33134714  3.0727408 ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -3.0725317 ]]  b1: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1495267]\n",
      "5000 cost:[ 0.00023352903 ]  W1: [[-0.77025205  0.8590644   0.22303277  0.33134714  3.1501734 ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -3.1502235 ]]  b1: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1498747]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    # cost를 minimize 한다\n",
    "    optimizer.minimize(cost_func,var_list=[W1,b1,W2,b2,W3,b3])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W1:',W1.numpy(),' b1:',b1.numpy())\n",
    "        \n",
    "print('***** Learning Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5449cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[-0.77025205  0.8590644   0.22303277  0.33134714  3.1501734 ]\n",
      " [ 0.5865573   0.30044103  0.585282   -1.365058   -3.1502235 ]]\n",
      "bias: [-1.0226775 -1.4043838 -0.9393954 -1.2653481  1.1498747]\n",
      "weight2: [[ 0.68929434  0.00758459 -0.3313842 ]\n",
      " [ 0.67215526 -0.12362287  0.42992517]\n",
      " [ 1.2553493  -1.4591074   0.1964497 ]\n",
      " [ 1.2258319  -0.14778678  0.644789  ]\n",
      " [-4.300522   -1.2172114  -1.0509079 ]]\n",
      "bias2: [ 4.9450154  5.2303734 -1.2743692]\n",
      "weight3: [[ 5.202628  ]\n",
      " [-4.3889832 ]\n",
      " [ 0.12368698]]\n",
      "bias3: [7.188945]\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수, weight과 bias 출력\n",
    "print('weight:', W1.numpy())\n",
    "print('bias:', b1.numpy())\n",
    "\n",
    "print('weight2:', W2.numpy())\n",
    "print('bias2:', b2.numpy())\n",
    "\n",
    "print('weight3:', W3.numpy())\n",
    "print('bias3:', b3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa14ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:\n",
      " [[6.6117456e-05]\n",
      " [9.9995279e-01]\n",
      " [9.9924564e-01]\n",
      " [6.6158202e-05]] \n",
      "Predict:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정 : accuracy computation\n",
    "def predict(X):\n",
    "    return tf.cast(hypothesis(X) > 0.5, dtype=tf.float32)  # 예측값을 0과 1로 변환\n",
    "\n",
    "# train 데이터로 검증\n",
    "preds = predict(x_train)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds,y_train), dtype=tf.float32))\n",
    "\n",
    "print(\"Hypothesis:\\n\",hypothesis(x_train).numpy(), \n",
    "      \"\\nPredict:\\n\",predict(x_train).numpy(),\n",
    "      \"\\nAccuracy:\",accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14e258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
